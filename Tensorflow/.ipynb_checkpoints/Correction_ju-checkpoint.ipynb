{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.3)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 모델 설계 단계 #\n",
    "\n",
    "repeatCount = 5\n",
    "\n",
    "batch_size = 10\n",
    "rnn_size = 10\n",
    "learing_rate = 0.01\n",
    "\n",
    "epoch = 700\n",
    "\n",
    "# ---------- RNN Network ---------- #\n",
    "\n",
    "# input place holders\n",
    "data = tf.placeholder(tf.float32, [None, 10, 1])\n",
    "p_data = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "# RNN Network\n",
    "rnn_cell = tf.contrib.rnn.BasicRNNCell(rnn_size)\n",
    "val, _state = tf.nn.dynamic_rnn(rnn_cell, data, dtype=tf.float32)\n",
    "pred = tf.contrib.layers.fully_connected(val[:, -1], 1, activation_fn=None)\n",
    "\n",
    "# cost\n",
    "cost_corr = tf.reduce_mean(tf.square(pred - p_data))\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learing_rate)\n",
    "train_corr = optimizer.minimize(cost_corr)\n",
    "\n",
    "# RMSE / MAE\n",
    "targets = tf.placeholder(tf.float32, [None, 1])\n",
    "predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))\n",
    "mae = tf.reduce_mean(tf.abs(targets - predictions))\n",
    "\n",
    "cIndex = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def NetworkFunc(step) :\n",
    "    print(\"step\", step+1, \"...\")\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "    # Training\n",
    "        for step in range(epoch) :\n",
    "            _, step_loss_corr = sess.run([train_corr, cost_corr], feed_dict={data:train_data, p_data:train_result})\n",
    "\n",
    "            #if step%500 == 0 and step != 0 :\n",
    "            #    print step,\", cost_lon :\", step_loss_lon\n",
    "    # Test\n",
    "        result = []\n",
    "\n",
    "        \n",
    "    # 데이터 보정\n",
    "        for i in range(0, 10) :\n",
    "            result.append(test_data[0][i])\n",
    "\n",
    "        for i in range(len(test_data)) :\n",
    "            #print(test_data)\n",
    "            std_val = np.std(test_data[i][0:])\n",
    "            variation = test_result[i] - test_data[i][-1]\n",
    "\n",
    "            if std_val < abs(variation) :\n",
    "                cIndex.append(i+11)\n",
    "                #print(test_data[i], test_data[i,0])\n",
    "                test_corr = sess.run(pred, feed_dict={data:[test_data[i]]})\n",
    "    # Set Predict Value\n",
    "                #corr_result = test_corr\n",
    "    # Set Original-Prediction Mid Value\n",
    "                corr_result = (test_corr + test_result[i])/2\n",
    "    # Set ( 2 * Predict + Original ) / 3 Value\n",
    "                #corr_result = (test_corr * 2 + test_result[i]) / 3\n",
    "    # Set ( 3 * Predict + Original ) / 4 Value\n",
    "                #corr_result = (test_corr * 3 + test_result[i]) / 4\n",
    "\n",
    "                result.append(sum(corr_result))\n",
    "                #print(test_corr, test_result[i], corr_result)\n",
    "                rest = 10 if (len(test_data)-i) > 10 else (len(test_data)-i)\n",
    "                num = 1;\n",
    "                for j in range(rest, 0, -1) :\n",
    "                    if i+num < len(test_data) :\n",
    "                        test_data[i+num, j-1] = corr_result\n",
    "                        num += 1\n",
    "            else :\n",
    "                result.append(test_result[i])\n",
    "\n",
    "            #print(i, ':', test_data[i][0:])\n",
    "            #print(variation)\n",
    "\n",
    "        #test_corr = sess.run(pred, feed_dict={data:test_data})\n",
    "        #np.savetxt(\"file1.csv\", test_lon, delimiter=\",\")\n",
    "        #mae_lon = sess.run(mae, feed_dict={targets:lon_test, predictions: test_lon})\n",
    "        #print \"MAE_lon :\", mae_lon\n",
    "\n",
    "        #print(type(test_corr))\n",
    "        #test_corr = 1\n",
    "    return result\n",
    "\n",
    "#test_pred = np.array(test_lon, test_lat)\n",
    "\n",
    "#writer = pd.ExcelWriter(fileName, engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 ...\n",
      "step 2 ...\n",
      "Time : 5.753504037857056\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "avg_corr = []\n",
    "#caseNum = '01'\n",
    "clist = ['01']\n",
    "#clist = ['01', '02', '03', '04', '05', '06', '07', '08']\n",
    "param = 'wind_u'\n",
    "\n",
    "for caseNum in clist :\n",
    "    testSet = open('./Data/DataForCorr/RNN/2016/case' + caseNum + '_' + param + '.dat')\n",
    "    trainSet = open('./Data/DataForCorr/RNN/2016/case' + caseNum + '_' + param + '.dat')\n",
    "    read_testSet = np.loadtxt(testSet)\n",
    "    read_trainSet = np.loadtxt(trainSet)\n",
    "\n",
    "    testSet.close()\n",
    "    trainSet.close()\n",
    "\n",
    "    #lon_def = 125.079590\n",
    "    #lat_def = 36.578830\n",
    "\n",
    "    fileName = 'correction_' + param + '_' + caseNum + '.dat'\n",
    "    ifileName = 'correction_' + param + '_' + caseNum + '_index.dat'\n",
    "\n",
    "    train_result = read_trainSet[:,-1]\n",
    "    train_data = read_trainSet[:,0:10]\n",
    "    test_result = read_testSet[:,-1]\n",
    "    test_data = read_testSet[:,0:10]\n",
    "\n",
    "    train_result = train_result.reshape(len(np.atleast_1d(train_result)), 1)\n",
    "    train_data = train_data.reshape(len(np.atleast_1d(train_data)), 10, 1)\n",
    "\n",
    "    test_result = test_result.reshape(len(np.atleast_1d(test_result)), 1)\n",
    "    test_data = test_data.reshape(len(np.atleast_1d(test_data)), 10, 1)\n",
    "\n",
    "    for count in range(2) :\n",
    "        test_corr = NetworkFunc(count)\n",
    "        avg_corr = test_corr\n",
    "        #np.savetxt('./Result/Temp/RNN/' + str(count) + '_' + fileName, test_corr, delimiter=\" \", fmt='%.4f');\n",
    "        #np.savetxt('./Result/Temp/RNN/' + str(count) + '_' + ifileName, cIndex, delimiter=\" \", fmt='%d');\n",
    "        cIndex = []\n",
    "        #df = pd.DataFrame(test_corr, columns=['wind_v'])\n",
    "        #sheet_name = caseNum + '_' + str(count+1)\n",
    "        #df.to_excel(writer, sheet_name)\n",
    "\n",
    "    #print(test_corr)\n",
    "    #avg_corr = [x / 2 for x in avg_corr]\n",
    "    np.savetxt('./Result/Temp/RNN/' + fileName, avg_corr, delimiter=\" \", fmt='%.4f');\n",
    "    #writer.save()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Time :\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
