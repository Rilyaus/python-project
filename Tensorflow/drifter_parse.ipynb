{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "float_formatter = lambda x: \"%.4f\" % x\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cNum = ['01', '02', '03', '04', '05', '06', '07', '08']\n",
    "\n",
    "for c in cNum :\n",
    "    data = open('./Data/Original2016/04-04-' + c + '.dat')\n",
    "    read_data = np.loadtxt(data, skiprows=1)\n",
    "    data.close()\n",
    "    \n",
    "    read_data_t = read_data[1:,10]\n",
    "    #read_data_t\n",
    "        \n",
    "    np.savetxt('./Data/Weka/Test_case' + c + '.dat', parse_data, delimiter=\" \", fmt=\"%.4f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cNum = ['01', '02', '03', '04', '05', '06', '07', '08']\n",
    "\n",
    "for c in cNum :\n",
    "    data = open('./Data/Original2016/04-04-' + c + '.dat')\n",
    "    read_data = np.loadtxt(data, skiprows=1)\n",
    "    data.close()\n",
    "        \n",
    "    \"\"\"read_data_t = read_data[:, :]\n",
    "    \n",
    "    parse_data = np.zeros((read_data_t.shape[0]-1,read_data_t.shape[1]-5))\n",
    "    for i in range(len(read_data)-1) :\n",
    "        #parse_data[i,0:4] = read_data_t[i, 0:4]\n",
    "        parse_data[i,0] = read_data_t[i+1,4] - read_data_t[i,4]\n",
    "        #parse_data[i,1] = read_data_t[i+1,5] - read_data_t[i,5]\n",
    "        parse_data[i,1] = read_data_t[i+1,6] - read_data_t[i,6]\n",
    "        parse_data[i,2] = read_data_t[i+1,7] - read_data_t[i,7]\n",
    "        parse_data[i,3:] = read_data_t[i,8:]\"\"\"\n",
    "\n",
    "    read_data_t = read_data[:,4:]\n",
    "    #read_data_t\n",
    "\n",
    "    parse_data = np.zeros((read_data_t.shape[0]-1,read_data_t.shape[1]-3))\n",
    "    for i in range(len(read_data)-1) :\n",
    "        #parse_data[i,0] = read_data_t[i+1,0] - read_data_t[i,0]\n",
    "        parse_data[i,0] = read_data_t[i+1,1] - read_data_t[i,1]\n",
    "        #parse_data[i,2] = read_data_t[i+1,2] - read_data_t[i,2]\n",
    "        #parse_data[i,3] = read_data_t[i+1,3] - read_data_t[i,3]\n",
    "        parse_data[i,1:] = read_data_t[i,4:]\n",
    "    \n",
    "    \"\"\"for i in range(len(read_data)-1) :\n",
    "        parse_data[i,0:4] = read_data_t[i+1,0:4] - read_data_t[i,0:4]\n",
    "        parse_data[i,4:] = read_data_t[i,4:]\"\"\"\n",
    "\n",
    "    #parse_data_lon = np.delete(parse_data, 1, 1)    # lon\n",
    "    #parse_data_lat = np.delete(parse_data, 0, 1)    # lat\n",
    "\n",
    "    #parse_data2 = np.concatenate((parse_data, parse_data))  # 배열 연결하기(붙이기)\n",
    "        \n",
    "    np.savetxt('./Data/Weka/lat_Test_case' + c + '.arff', parse_data, delimiter=\" , \", fmt=\"%.4f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = open('./Data/Original2016/04-04-01.dat')\n",
    "read_data = np.loadtxt(data, skiprows=1)\n",
    "data.close()\n",
    "\n",
    "read_data_t = read_data[:, :]\n",
    "parse_data = np.zeros((read_data_t.shape[0]-1,read_data_t.shape[1]))\n",
    "for i in range(len(read_data)-1) :\n",
    "    parse_data[i,0:4] = read_data_t[i, 0:4]\n",
    "    parse_data[i,4] = read_data_t[i+1,4] - read_data_t[i,4]\n",
    "    parse_data[i,5] = read_data_t[i+1,5] - read_data_t[i,5]\n",
    "    parse_data[i,6] = read_data_t[i+1,6] - read_data_t[i,6]\n",
    "    parse_data[i,7] = read_data_t[i+1,7] - read_data_t[i,7]\n",
    "    parse_data[i,8:] = read_data_t[i,8:]\n",
    "    \n",
    "for i in range(len(read_data)-1) :\n",
    "    parse_data[i, 0] = int(parse_data[i, 0])\n",
    "    \n",
    "int(parse_data[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cNum = ['01', '02', '03', '04', '05', '06', '07', '08']\n",
    "\n",
    "#parse_data2 = np.empty((0, read_data_t.shape[1]-2))\n",
    "for c in cNum :\n",
    "    parse_data2 = np.empty((0, read_data_t.shape[1]-3))\n",
    "    for c2 in cNum :\n",
    "        if c2 != c :\n",
    "            data = open('./Data/Original2016/04-04-' + c2 + '.dat')\n",
    "            read_data = np.loadtxt(data, skiprows=1)\n",
    "            data.close()\n",
    "\n",
    "            read_data_t = read_data[:,4:]\n",
    "            #read_data_t\n",
    "\n",
    "            parse_data = np.zeros((read_data_t.shape[0]-1,read_data_t.shape[1]-3))\n",
    "            for i in range(len(read_data)-1) :\n",
    "                parse_data[i,0] = read_data_t[i+1,0] - read_data_t[i,0]\n",
    "                #parse_data[i,0] = read_data_t[i+1,1] - read_data_t[i,1]\n",
    "                #parse_data[i,2] = read_data_t[i+1,2] - read_data_t[i,2]\n",
    "                #parse_data[i,3] = read_data_t[i+1,3] - read_data_t[i,3]\n",
    "                parse_data[i,1:] = read_data_t[i,4:]\n",
    "                \n",
    "            parse_data2 = np.concatenate((parse_data2, parse_data))\n",
    "    np.savetxt('./Data/Weka/lon_Train_case' + c + '.arff', parse_data2, delimiter=\" , \", fmt=\"%.4f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ee8a652da01e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mparse_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_data_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mparse_data2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparse_data2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Data/Weka/Train_case'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.dat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_data2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"%.4f\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "cNum = ['01', '02', '03', '04', '05', '06', '07', '08']\n",
    "\n",
    "#parse_data2 = np.empty((0, read_data_t.shape[1]-2))\n",
    "for c in cNum :\n",
    "    parse_data2 = np.empty((0, read_data_t.shape[1]-2))\n",
    "    for c2 in cNum :\n",
    "        if c2 != c :\n",
    "            data = open('./Data/Original2016/04-04-' + c2 + '.dat')\n",
    "            read_data = np.loadtxt(data, skiprows=1)\n",
    "            data.close()\n",
    "\n",
    "            read_data_t = read_data[:,4:]\n",
    "            #read_data_t\n",
    "\n",
    "            parse_data = np.zeros((read_data_t.shape[0]-1,read_data_t.shape[1]-2))\n",
    "            for i in range(len(read_data)-1) :\n",
    "                parse_data[i,0] = read_data_t[i+1,0] - read_data_t[i,0]\n",
    "                parse_data[i,1] = read_data_t[i+1,1] - read_data_t[i,1]\n",
    "                #parse_data[i,2] = read_data_t[i+1,2] - read_data_t[i,2]\n",
    "                #parse_data[i,3] = read_data_t[i+1,3] - read_data_t[i,3]\n",
    "                parse_data[i,2:] = read_data_t[i,4:]\n",
    "                \n",
    "            parse_data2 = np.concatenate((parse_data2, parse_data))\n",
    "    np.savetxt('./Data/Weka/Train_case' + c + '.dat', parse_data2, delimiter=\" \", fmt=\"%.4f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000, 0.0000, 0.0000],\n",
       "       [0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1 = np.zeros((2, 3))\n",
    "temp2 = np.empty((0, 3))\n",
    "temp2 = np.concatenate((temp2, temp1))\n",
    "\n",
    "temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer  = pd.ExcelWriter('corr_wind_u.xlsx', engine='xlsxwriter')\n",
    "\n",
    "df = pd.DataFrame(p_wind_u)\n",
    "sheet_name = 'sheet1'\n",
    "df.to_excel(writer, sheet_name)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer  = pd.ExcelWriter('corr_wind_v.xlsx', engine='xlsxwriter')\n",
    "\n",
    "df = pd.DataFrame(p_wind_v)\n",
    "sheet_name = 'sheet1'\n",
    "df.to_excel(writer, sheet_name)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# autoencoder Parser for RNN experiment\n",
    "case_num = '08'\n",
    "\n",
    "d_coord = open('./Data/ParseNew/Test_case' + case_num + '.dat')\n",
    "d_velo_u = open('./Result/autoencoder/Corrected/' + case_num + '/case' + case_num + '_velo_u.dat')\n",
    "d_velo_v = open('./Result/autoencoder/Corrected/' + case_num + '/case' + case_num + '_velo_v.dat')\n",
    "d_wind_u = open('./Result/autoencoder/Corrected/' + case_num + '/case' + case_num + '_wind_u.dat')\n",
    "d_wind_v = open('./Result/autoencoder/Corrected/' + case_num + '/case' + case_num + '_wind_v.dat')\n",
    "\n",
    "read_coord = np.loadtxt(d_coord)\n",
    "read_velo_u = np.loadtxt(d_velo_u)\n",
    "read_velo_v = np.loadtxt(d_velo_v)\n",
    "read_wind_u = np.loadtxt(d_wind_u)\n",
    "read_wind_v = np.loadtxt(d_wind_v)\n",
    "\n",
    "d_coord.close()\n",
    "d_velo_u.close()\n",
    "d_velo_v.close()\n",
    "d_wind_u.close()\n",
    "d_wind_v.close()\n",
    "\n",
    "parse_data = np.zeros((read_velo_u.size-1, 6))\n",
    "\n",
    "for i in range(len(read_velo_u)-1) :\n",
    "    parse_data[i,:2] = read_coord[i,:2]\n",
    "    parse_data[i,2] = read_velo_u[i]\n",
    "    parse_data[i,3] = read_velo_v[i]\n",
    "    parse_data[i,4] = read_wind_u[i]\n",
    "    parse_data[i,5] = read_wind_v[i]\n",
    "\n",
    "np.savetxt('./Data/Autoencoder/corr_case' + case_num + '.dat', parse_data, delimiter=\" \", fmt=\"%.4f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for autoencoder experiment\n",
    "case_num = '02'\n",
    "\n",
    "data = open('./Data/NewData/04-04-' + case_num + '.dat')\n",
    "read_data = np.loadtxt(data, skiprows=1)\n",
    "data.close()\n",
    "\n",
    "read_data_t = read_data[:, 8:]\n",
    "\n",
    "#print(read_data_t[:, 1])\n",
    "np.savetxt('./Data/Autoencoder/Test/case' + case_num + '_velo_u.dat', read_data_t[:, 0], delimiter=\" \", fmt=\"%.4f\")\n",
    "np.savetxt('./Data/Autoencoder/Test/case' + case_num + '_velo_v.dat', read_data_t[:, 1], delimiter=\" \", fmt=\"%.4f\")\n",
    "np.savetxt('./Data/Autoencoder/Test/case' + case_num + '_wind_u.dat', read_data_t[:, 2], delimiter=\" \", fmt=\"%.4f\")\n",
    "np.savetxt('./Data/Autoencoder/Test/case' + case_num + '_wind_v.dat', read_data_t[:, 3], delimiter=\" \", fmt=\"%.4f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
